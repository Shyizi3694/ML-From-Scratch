{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chapter 0: 项目准备、框架与预处理",
   "id": "309a7d7bf9fa76e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "模仿 Scikit-Learn 的项目结构，从零开始完成一个机器学习代码库不是一个简单的任务。在对模型的创建、训练和评估之前，我们需要先完成一些准备工作。这个章节将介绍如何设置项目结构、创建数据集类以及实现数据预处理的基本功能。",
   "id": "7c164b10191d517c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Section 0.1: 环境准备",
   "id": "4ec83539f6632dbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Python 是一个强大的编程语言，拥有丰富的库和工具，适合用于机器学习和数据科学，使用它作为本次项目的语言是很自然的。选择 Python 3.12.3 WSL 作为开发环境，能够充分利用其最新的特性和性能改进。",
   "id": "a44dd4d4a21adbae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "使用 PyCharm 作为 IDE，在创建工程时能够自动创建虚拟环境和一些必要的配置文件如：\n",
    "- `.gitignore`：用于指定哪些文件或目录不应该被 Git 跟踪。\n",
    "- `requirements.txt`：列出项目所需的 Python 包及其版本，便于环境的重现。\n",
    "- `README.md`：提供项目的基本信息和使用说明。\n",
    "- `LICENSE`：指定项目的许可证类型，确保代码的使用和分发符合相关法律���规。\n",
    "- `pyproject.toml`：用于定义项目的元数据和依赖关系，符合 PEP 518 标准。"
   ],
   "id": "3fbc152f665a952f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "以下是 `requirements.txt` 的内容，列出了除了 IDE 自带的库以外，项目仍需的 Python 包及其版本：\n",
    "```plaintext\n",
    "# 核心计算与数据科学库\n",
    "numpy\n",
    "scikit-learn\n",
    "\n",
    "# Jupyter 报告与可视化\n",
    "jupyterlab\n",
    "matplotlib\n",
    "seaborn\n",
    "\n",
    "# 代码质量工具\n",
    "black\n",
    "ruff\n",
    "```"
   ],
   "id": "d79e60256b827d5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 在环境准备中遇到的问题：IDE 无法自动创建虚拟环境并激活，需要手动创建和激活虚拟环境。\n",
    "\n",
    "----\n"
   ],
   "id": "34a5b226e71fd3a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Section 0.2: 项目结构",
   "id": "7c6b33803b586374"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "以下是项目的目录结构，仿照 Scikit-Learn 的项目结构设计，包含了核心代码、测试代码和文档等部分：\n",
    "```plaintext\n",
    ".\n",
    "├── LICENSE\n",
    "├── README.md\n",
    "├── build_docs.sh\n",
    "├── main.py\n",
    "├── notebooks\n",
    "│   ├── 00_Framework_And_Preprocessing.ipynb\n",
    "│   ├── ...\n",
    "│   └── notebook_demo.ipynb\n",
    "├── pyproject.toml\n",
    "├── requirements.txt\n",
    "└── src\n",
    "    └── mlfromscratch\n",
    "        ├── __init__.py\n",
    "        ├── compose\n",
    "        │   ├── __init__.py\n",
    "        │   ├── _column_transformer.py\n",
    "        │   └── _pipeline.py\n",
    "        ├── metrics\n",
    "        │   ├── __init__.py\n",
    "        │   ├── classification.py\n",
    "        │   └── regression.py\n",
    "        ├── models\n",
    "        │   ├── __init__.py\n",
    "        │   ├── linear_regression.py\n",
    "        │   └── ...\n",
    "        ├── optim\n",
    "        │   ├── __init__.py\n",
    "        │   ├── gradient_descent.py\n",
    "        │   └── ...\n",
    "        ├── preprocessing\n",
    "        │   ├── __init__.py\n",
    "        │   ├── encoder.py\n",
    "        │   ├── imputer.py\n",
    "        │   └── scaler.py\n",
    "        └── utils\n",
    "            ├── __init__.py\n",
    "            ├── base.py\n",
    "            ├── data_loader.py\n",
    "            └── validation.py\n",
    "```"
   ],
   "id": "b16657e8df00cab9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `src/mlfromscratch/compose`：组合逻辑，包含管道和列转换器的实现。\n",
    "- `src/mlfromscratch/metrics`：评估指标的实现，包括分类和回归指标。\n",
    "- `src/mlfromscratch/models`：模型的实现。\n",
    "- `src/mlfromscratch/optim`：优化算法的实现。\n",
    "- `src/mlfromscratch/preprocessing`：数据预处理的实现，包括编码器、插补器和缩放器。\n",
    "- `src/mlfromscratch/utils`：工具类和函数的实现，包括基类、数据加载器和验证器。\n",
    "\n",
    "----\n"
   ],
   "id": "a6bbc8f9b740e7c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Section 0.3: 模型基类的设计",
   "id": "9986933c2d487399"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Scikit-Learn 的诸多模型可以抽象出一些通用的接口和方法，这些方法可以在一个基类中实现，以便于其他模型继承和复用。本项目在 `src/mlfromscratch/utils/base.py` 中定义了一个 `BaseEstimator` 类，作为所有模型的基类。这个基类包含了以下方法：\n",
    "- `@abstractmethod fit(X, y, **fit_params) -> self`：训练模型，其中 `y` 和 `**fit_params` 是可选参数。\n",
    "- `@abstractmethod predict(X) -> np.ndarray`：使用训练好的模型进行预测。\n",
    "- `fit_predict(X, y=None, **fit_params) -> np.ndarray`：先训练模型再进行预测，返回预测结果。\n",
    "- `get_params(deep=True) -> dict` & `set_params(**params) -> self`：模型参数的 getter 和 setter。\n",
    "- `__repr__()`：返回模型的字符串表示，便于调试和日志记录。\n",
    "\n",
    "其他方法是上述几个方法的辅助方法。其中 `fit` 和 `predict` 是**抽象方法**，要求派生类必须实现。\n",
    "\n",
    "----\n"
   ],
   "id": "b1504675898472d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Section 0.4: 评估指标函数的设计",
   "id": "5ce8e070da54d5da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "分类和回归模型的评估指标有着不同的计算方式，这是分类和回归本身的性质决定的：分类模型根据训练得出的参数，对输入数据进行分类预测，输出类别标签；而回归模型则输出连续值。本项目的评估指标函数设计遵循 Scikit-Learn 的风格，位于 `src/mlfromscratch/metrics` 目录下，包含`classification.py` 和 `regression.py` 两个模块。",
   "id": "324ad4285a515c64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 分类评估指标",
   "id": "21b4997e60459cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "前面提到，分类模型输出类别标签的数组，在评估时需要将其与真实标签进行比较。对于分类问题，关注分类是否正确（预测是否严格与实际相等）的意义远远大于计算预测结果与实际的距离。\n",
    "\n",
    "以二分类问题为例，预测的结果有以下四种情况：\n",
    "- True Positive (TP)：预测为正类，实际也是正类。\n",
    "- True Negative (TN)：预测为负类，实际也是负类。\n",
    "- False Positive (FP)：预测为正类，实际是负类（也称为假阳性）。\n",
    "- False Negative (FN)：预测为负类，实际是正类（也称为假阴性）。"
   ],
   "id": "ad2fd507214f93af"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "根据这四个量可以计算出常用的三个评估指标：\n",
    "- Accuracy（准确率）：正确预测的比例。\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "- Precision（精确率）：预测为正类的样本中，实际为正类的比例。\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "- Recall（召回率）：实际为正类的样本中，预测为正类的比例。\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$"
   ],
   "id": "536988fb1571f83"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "由 Precision 和 Recall 可以进一步计算 F1 Score（F1 分数），它是 Precision 和 Recall 的调和平均数，综合考虑了两者的平衡性：\n",
    "$$\n",
    "\\text{F1 Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$"
   ],
   "id": "f67783ad4e780e51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "对于 `classification.py`，实现了以下评估指标函数：\n",
    "- `accuracy_score(y_true, y_pred) -> float`��计算分类准确率。\n",
    "- `precision_score(y_true, y_pred) -> float`：计算精确率。\n",
    "- `recall_score(y_true, y_pred) -> float`：计算召回率。\n",
    "- `f1_score(y_true, y_pred) -> float`：计算 F1 分数。\n",
    "\n",
    "以及其他辅助函数：\n",
    "- `_calculate_confusion_matrix_values(y_true, y_pred) -> tuple`：计算混淆矩阵的各个值，返回展平后的数组。\n",
    "- `_validate_inputs(y_true, y_pred) -> tuple`：验证输入的标签和预测结果是否有效。"
   ],
   "id": "6939d71ea8e7027b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 回归评估指标",
   "id": "1a85213f49f2a429"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "对于回归问题，预测的结果是连续值，因此评估指标的计算方式与分类问题有所不同，通常用预测结果与实际值之间的距离来衡量模型的性能。常用的回归评估指标包括：\n",
    "- Mean Squared Error (MSE)：均方误差，计算预测值与实际值之间的平方差的平均值。\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "其中 $y_i$ 是实际值，$\\hat{y}_i$ 是预测值，$n$ 是样本数量。\n",
    "\n",
    "- Root Mean Squared Error (RMSE)：均方根误差，是 MSE 的平方根，具有与原始数据相同的单位。\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2}\n",
    "$$"
   ],
   "id": "4475504f85e584cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "进一步，可以用 R-squared（$R^2$）来衡量��型的拟合优度，它表示模型解释的方差占总方差的比例：\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\text{MSE}}{\\text{Var}(y)}\n",
    "$$\n",
    "其中 $\\text{Var}(y)$ 是实际值的方差。"
   ],
   "id": "f75bffdc5bb86571"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "对于 `regression.py`，实现了以下评估指标函数：\n",
    "- `mean_squared_error(y_true, y_pred) -> float`：计算均方误差。\n",
    "- `root_mean_squared_error(y_true, y_pred) -> float`：计算均方根误差。\n",
    "- `r_squared(y_true, y_pred) -> float`：计算 $R^2$ 值。"
   ],
   "id": "bb7aaf6721ffe75c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 使用 Mixin 将评估指标添加到模型类",
   "id": "d4ebd8323c4d9575"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "分类问题和回归问题通常各自具有默认的评估指标，如分类问题的默认评估指标是准确率（Accuracy），回归问题的默认评估指标是 $R^2$，因此在模型类中可以通过 Mixin 的方式将这些评估指标方法添加到模型类中。这样，模型类就可以直接调用这些评估指标方法进行评估，而不需要额外的导入或实现。",
   "id": "c6de1e5611889df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "由此设计出 `src/mlfromscratch/utils/base.py` 中的 `ClassifierMixin` 和 `RegressorMixin` 类，分别包含了分类和回归的评估指标方法，并统一命名为 `score(self, X: np.ndarray, y: np.ndarray) -> float`，一体化训练、预测和评估。这些 Mixin 类可以被模型类继承，从而获得直接获得评估结果的方法。",
   "id": "4b6d9b44548768d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "然而笔者在实际使用过程中发现，为了避免一些不必要的警告信息影响整体美观，需要让 Mixin 类继承 `BaseEstimator` 类，并且如果需要要求派生类必须实现一些方法（如转换器类 Transformer 要求其派生类实现 transform() 方法），应当将对应 Mixin 类设计为抽象类（ABC）。即以如下形式出现：",
   "id": "4328dbac24ff50af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T03:05:48.848997Z",
     "start_time": "2025-08-11T03:05:48.813041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.mlfromscratch.utils.base import BaseEstimator\n",
    "\n",
    "\n",
    "class MyMixin(BaseEstimator, ABC):\n",
    "    @abstractmethod\n",
    "    def ABCMethod(self):\n",
    "        \"\"\"抽象方法，派生类必须实现\"\"\"\n",
    "        pass\n",
    "    def score(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"计算模型的评估指标\"\"\"\n",
    "        pass"
   ],
   "id": "c0d3d7b64dbdbb1f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "在设计模型时，由于 Mixin 已经继承了 `BaseEstimator`，因此模型类只需要继承 Mixin 类即可获得评估指标方法，但是为了保持代码的一致性和可读性，笔者仍然建议模型类同时继承 `BaseEstimator` 类。这样可以确保模型类具有统一的接口和方法，同时也能避免一些潜在的错误。",
   "id": "dfcdd7dbaa9350c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "需要注意，模型在同时继承 `BaseEstimator` 和 Mixin 类时，必须将 Mixin 类放在继承列表的前面，否则会导致 `TypeError: Cannot create a consistent method resolution` 错误。这是因为 Python 的方法解析顺序（MRO）决定了在调用方法时，首先查找的是 Mixin 类中的方法，然后才是 `BaseEstimator` 类中的方法。如果顺序颠倒，可能会导致无法找到某些方法，从而引发错误。",
   "id": "c9daf45819ff163"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "事实上，这样的写法与 Mixin 一开始的设计理念有所出入，因为 Mixin 的目的是为了提供额外的功能，而不是作为一个完整的类来使用。因此这种为了避免警告而将 Mixin 设计为抽象类的做法，仍然有待商榷。",
   "id": "bb85eb7b34544da4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T03:05:48.864942Z",
     "start_time": "2025-08-11T03:05:48.860832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 这是一个使用 Mixin 的示例，假设我们需要设计一个分类模型类和一个回归模型类。\n",
    "from src.mlfromscratch.utils.base import BaseEstimator\n",
    "from src.mlfromscratch.utils.base import ClassifierMixin, RegressorMixin\n",
    "\n",
    "# 同时继承 BaseEstimator 和 ClassifierMixin 的模型类\n",
    "class MyClassifier(ClassifierMixin, BaseEstimator):\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        # 模型训练逻辑\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 模型预测逻辑\n",
    "        return np.argmax(X, axis=1) # 示例返回值，假设 X 是一个二维数组，每行是一个样本的特征向量\n",
    "\n",
    "# 同时继承 BaseEstimator 和 RegressorMixin 的模型类\n",
    "class MyRegressor(RegressorMixin, BaseEstimator):\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        # 模型训练逻辑\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 模型预测逻辑\n",
    "        return np.mean(X, axis=1) # 示例返回值，假设 X 是一个二维数组，每行是一个样本的特征向量\n"
   ],
   "id": "29ea4ce0bc6520e5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "我们来测试一下这些模型类的评估指标方法是否正常工作：",
   "id": "1e63d2caaec53013"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T03:05:48.883889Z",
     "start_time": "2025-08-11T03:05:48.877960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# 创建一个分类模型实例\n",
    "classifier = MyClassifier()\n",
    "# 训练模型\n",
    "classifier.fit(np.array([[0, 1], [1, 0], [1, 1], [0, 0]]), np.array([0, 1, 1, 0]))\n",
    "# 预测结果\n",
    "y_pred = classifier.predict(np.array([[0, 1], [1, 0],[1, 1], [0, 0]]))\n",
    "# 计算评估指标\n",
    "accuracy = classifier.score(np.array([[0, 1], [1, 0],[1, 1], [0, 0]]), np.array([0, 1, 1, 0]))\n",
    "print(f\"分类模型的准确率: {accuracy}\")\n",
    "\n",
    "# 创建一个回归模型实例\n",
    "regressor = MyRegressor()\n",
    "# 训练模型\n",
    "regressor.fit(np.array([[0, 1], [1, 0], [1, 1], [0, 0]]), np.array([0.5, 0.5, 1.0, 0.0]))\n",
    "# 预测结果\n",
    "y_pred = regressor.predict(np.array([[0, 1], [1, 0],[1, 1], [0, 0]]))\n",
    "# 计算评估指标\n",
    "r2 = regressor.score(np.array([[0, 1], [1, 0],[1, 1], [0, 0]]), np.array([0.5, 0.5, 1.0, 0.0]))\n",
    "print(f\"回归模型的 R^2 值: {r2}\")"
   ],
   "id": "480c2397d51c5f1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类模型的准确率: 0.25\n",
      "回归模型的 R^2 值: 1.0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "----",
   "id": "a1ca2b4dd8c33e72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Section 0.5: 数据集导入函数",
   "id": "bdc5862c99624a49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "模型的设计和测试是密不可分的，模型的设计完成后，需要使用合适的数据集进行训练和测试。注意这里我们并不是为了获得一个很好的效果，这取决于模型本身和参数的选择。我们只需要利用数据集来检验模型的逻辑功能是否正常，是否能够正确地进行训练和预测。",
   "id": "b2fcdaa4cd8f0488"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "所幸，Scikit-Learn 提供了许多常用的数据集，可以直接导入使用。为了方便起见，我们在 `src/mlfromscratch/utils/data_loader.py` 中实现了一个数据集导入函数 `load_dataset(name: str, **kwargs) -> tuple`，可以根据数据集的名称加载相应的��据集，并返回特征矩阵和标签向量。",
   "id": "7e127270a089e1e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`data_loader.py` 中实现了以下数据集的自动导入功能：\n",
    "- `load_regression_data(n_samples, n_features, random_state)`：生成随机回归数据集。\n",
    "- `load_classification_data(n_samples, n_features, random_state)`：生成随机分类数据集。\n",
    "- `load_moons_data(n_samples, noise, random_state)`：生成双月形分类数据集。\n",
    "- `load_circles_data(n_samples, noise, random_state)`：生成同心圆分类数据集。\n",
    "- `load_blobs_data(n_samples, noise, random_state)`：生成聚类数据集。\n",
    "\n",
    "以下是一些真实数据集的加载函数：\n",
    "- `load_diabetes_data()`：加载糖尿病数据集。\n",
    "- `load_iris_data()`：加载鸢尾花数据集。\n",
    "- `load_wine_data()`：加载葡萄酒数据集。\n",
    "- `load_breast_cancer_data()`：加载乳腺癌数据集。\n",
    "\n",
    "另外还具备一个返回可用数据集名称的函数 `get_available_datasets() -> list`，便于用户查询。\n",
    "\n",
    "----\n"
   ],
   "id": "19b460a13d25880b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Section 0.6: 数据预处理功能",
   "id": "b39f2a68821db7a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "通过数据加载功能获取的数据集通常需要进行一些预处理操作，以便于模型的训练和测试。Scikit-Learn 提供了许多常用的数据预处理方法，如特征缩放、编码、插补等。本项目在 `src/mlfromscratch/preprocessing` 目录下实现了这些常用的预处理功能。",
   "id": "342cd3e136417307"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "所有的预处理器除了是一个基估计器外，都必须是一个转换器（Transformer），即除了 `fit()` 方法外，还必须实现 `transform(X: np.ndarray) -> np.ndarray` 方法。这个方法接受一个特征矩阵 `X`，并返回经过预处理后的特征矩阵。",
   "id": "8dfb0991240de6a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "转换器的设计也采用了 Mixin 的方式，将预处理器的通用接口和方法抽象出来，便于其他转换器继承和复用。所有的预处理器都继承自 `BaseEstimator` 类，并额外将 `transform()` 方法设置为抽象方法，要求派生类必须实现，并且直接提供 `fit_transform()` 方法，便于一体化操作。所有的转换器都继承自 `TransformerMixin` 类。",
   "id": "85eea6ae1fdd0edb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 插补器",
   "id": "886de33834c9a918"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "在将原始的 `.csv` 文件转为 Pandas DataFrame 时，可能会遇到缺失值（NaN）。为了处理这些缺失值，我们可以使用插补器（Imputer）来填充缺失值。Scikit-Learn 提供了 `SimpleImputer` 类，可以根据指定的策略（如均值、中位数、众数等）来填充缺失值。",
   "id": "2d9e6eb65eb02e06"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`SimpleImputer` 类的实现位于 `src/mlfromscratch/preprocessing/imputer.py` 中，私有属性如下：\n",
    "- `strategy`：插补策略，默认为 `'mean'`，可选值包括 `'mean'`、`'median'` 和`'most_frequent'`。\n",
    "- `statistics_`：存储每列的插补统计量，如均值、中位数或众数。\n",
    "\n",
    "方法如下：\n",
    "- `__init__(self, strategy: str = 'mean')`：初始化插补器，指定插补策略。\n",
    "- `fit(self, X: np.ndarray, y: Optional[np.ndarray] = None) -> self`：计算插补所需的统计量（如均值、中位数等）。\n",
    "- `transform(self, X: np.ndarray) -> np.ndarray`：根据计算的统计量填充缺失值。\n",
    "\n",
    "另外，当策略为众数时，`fit()` 调用辅助函数 `_calculate_most_frequent(X: np.ndarray) -> np.ndarray` 来计算每列的众数。"
   ],
   "id": "b081d37a8beb7dc0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "其他插补器如 `KNNImputer` 和 `IterativeImputer` 也可以在 `src/mlfromscratch/preprocessing/imputer.py` 中实现，前者使用 KNN 算法进行插补，后者使用迭代算法进行插补。",
   "id": "d5c180e88bf09017"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 编码器",
   "id": "27bb2ef3b928440f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "并非所有的属性的值都能使用数值方法处理，分类属性的值通常是字符串或类别标签，这些值需要转换为数值才能用于模型训练，如“猫”“狗”“鸟”等。我们需要对这些非数值的属性值进行合适的编码，以便于模型的训练和预测。",
   "id": "98ab3c03c5422074"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "独热编码是一种常用的编码方法，它将每个类别值转换为一个独立的二进制特征。如一个动物类型属性，包含“猫”“狗”“鸟”三个类别，特征矩阵示例如下：",
   "id": "5fb329378e92d4c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| 样本序号 | 动物类别 |\n",
    "|------|------|\n",
    "| 1    | 猫    |\n",
    "| 2    | 狗    |\n",
    "| 3    | 鸟    |\n",
    "| 4    | 猫    |\n",
    "| 5    | 狗    |\n",
    "| 6    | 鸟    |"
   ],
   "id": "1dc8abed88e66c30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "独热编码后的特征矩阵如下：",
   "id": "5d3581f1c5da009"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| 样本序号 | 动物类别（猫） | 动物类别（狗） | 动物类别（鸟） |\n",
    "|------|---------|---------|---------|\n",
    "| 1    | 1       | 0       | 0       |\n",
    "| 2    | 0       | 1       | 0       |\n",
    "| 3    | 0       | 0       | 1       |\n",
    "| 4    | 1       | 0       | 0       |\n",
    "| 5    | 0       | 1       | 0       |\n",
    "| 6    | 0       | 0       | 1       |\n",
    "\n",
    "表中的 1 表示该样本属于该类别，0 表示不属于该类别。这样，每个类别值都被转换为一个独立的二进制特征，便于模型的训练和预测。"
   ],
   "id": "55256c3f2d513e38"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`OneHotEncoder` 类的实现位于 `src/mlfromscratch/preprocessing/encoder.py` 中，私有属性如下：\n",
    "- `categories_`：存储每列的唯一类别值。\n",
    "\n",
    "方法如下：\n",
    "- `__init__(self)`： 初始化独热编码器。\n",
    "- `fit(self, X: np.ndarray, _y: np.ndarray = None, **_fit_params) -> self`：计算每列的唯一类别值，存储在 `self.categories_` 中。\n",
    "- `transform(self, X: np.ndarray) -> np.ndarray`：将类别值转换为独热编码形式。\n",
    "- `inverse_transform(self, X: np.ndarray) -> np.ndarray`：将独热编码形式转换回原始类别值。\n",
    "\n",
    "需要注意的是，这里 `OneHotEncoder` 并没有检验输入的待转��特征是否是非数值属性，也没有对输入是否为 NaN 进行前置检验，而是在过程中抛出错误。这是为了让 `OneHotEncoder` 专注于编码的任务，将数据的清洗与分类交给上一层模块来调度。"
   ],
   "id": "fcb0df3db722827b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "其他编码器如 `OrdinalEncoder` 和 `LabelEncoder` 也可以在 `src/mlfromscratch/preprocessing/encoder.py` 中实现，前者将类别值转换为整数，后者将类别标签转换为整数。",
   "id": "6aeb7d3b21b8f205"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 缩放器",
   "id": "f9df35ac8f66cfc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "缩放器的功能是将特征矩阵中的数值特征进行缩放，使其具有相同的尺度。常用的缩放方法包括标准化（Standardization）和归一化（Normalization）。标准化将特征值转换为均值为 0、方差为 1 的分布，而归一化将特征值缩放到指定的范围内（如 [0, 1]）。",
   "id": "c5104ff7b6227906"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "对于某一列特征，通过如下方式计算其均值和标准差：\n",
    "$$\n",
    "\\text{mean} = \\frac{1}{n} \\sum_{i=1}^n x_i\n",
    "$$\n",
    "$$\n",
    "\\text{std} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\text{mean})^2}\n",
    "$$\n",
    "\n",
    "其中 $x_i$ 是该列特征的第 $i$ 个值，$n$ 是样本数量。标准化后的特征值计算公式为：\n",
    "$$\\text{standardized\\_value} = \\frac{x_i - \\text{mean}}{\\text{std}}$$"
   ],
   "id": "87cd103f38f8362a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`StandardScaler` 类的实现位于 `src/mlfromscratch/preprocessing/scaler.py` 中，私有属性如下：\n",
    "- `mean_`：存储每列特征的均值。\n",
    "- `scale_`：存储每列特征的标准差。\n",
    "\n",
    "方法如下：\n",
    "- `__init__(self)`：初始化标准化缩放器。\n",
    "- `fit(self, X: np.ndarray, y: Optional[np.ndarray] = None) -> self`：计算每列特征的均值和标准差，存储在 `self.mean_` 和 `self.scale_` 中。\n",
    "- `transform(self, X: np.ndarray) -> np.ndarray`：将特征值转换为标准化形式。\n",
    "- `inverse_transform(self, X: np.ndarray) -> np.ndarray`：将标准化形式转换回原始特征值。\n",
    "\n",
    "property 如下：\n",
    "- `n_features_(self) -> int`：返回特征矩阵的列数，即特征的数量。"
   ],
   "id": "77cea247b7d285b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "其他缩放器如 `MinMaxScaler` 和 `RobustScaler` 也可以在 `src/mlfromscratch/preprocessing/scaler.py` 中实现，前者将特征值缩放到指定的范围内（如 [0, 1]），后者使用中位数和四分位数进行缩放，适用于存在异常值的情况。\n",
    "\n",
    "----\n"
   ],
   "id": "21971b74e3aa60aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Section 0.7: 更专业的工作流：组合",
   "id": "6379be840c53d331"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "对于机器学习工作流，通常需要将多个预处理步骤组合在一起，以便于模型的训练和预测。设想一个特征矩阵，可以串行地对其进行插补、编��和缩放等预处理操作，也可以并行地对其中的不同特征列进行不同的预处理操作。从这个角度出发，可以抽象出组合器（Composer）的概念，将多个预处理步骤组合在一起，形成一个完整的工作流。",
   "id": "8aafa1418884f42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "前述“串行”和“并行”的两种组合方式分别由 `Pipeline` 和 `ColumnTransformer` 类来实现。`Pipeline` 类用于将多个预处理步骤串行地组合在一起，而 `ColumnTransformer` 类用于对特征矩阵的不同列进行不同的预处理操作。",
   "id": "33c810a4c4d79eb7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pipeline",
   "id": "2a2e640251ed544c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "为了实现所谓“串行”的组合，`Pipeline` 类需要将多个预处理步骤按顺序组合在一起，即需要传入一系列转换器，以及用于最后一个步骤的预测模型。同样地，`Pipeline` 类也需要继承 `BaseEstimator` 类，并实现 `fit()`、`predict()` 方法，来统一地处理多个预处理步骤和模型的训练和预测。",
   "id": "50b3b6f3b2ba0e13"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`Pipeline` 类的实现位于 `src/mlfromscratch/compose/_pipeline.py` 中，私有属性如下：\n",
    "- `steps_`：存储预处理步骤和模型的列表，每个元素是一个元组，包含步骤名称和对应的转换器或模型。\n",
    "\n",
    "方法如下：\n",
    "- `__init__(self, steps: list)`：初始化管道，传入预处理步骤和模型的列表。\n",
    "- `fit(self, X: np.ndarray, y: np.ndarray = None, **fit_params) -> self`：按顺序调用每个预处理步骤的 `fit()` 方法，并将结果传递给下一个步骤，最后调用模型的 `fit()` 方法。\n",
    "- `predict(self, X: np.ndarray) -> np.ndarray`：按顺序调用每个预处理步骤的 `transform()` 方法，并将结果传递给模型的 `predict()` 方法，返回最终的预测结果。\n",
    "\n",
    "重载的方法：\n",
    "- `get_params(self, deep=True) -> dict`：返回管道中所有步骤的参数，便于参数的获取和设置。\n",
    "- `set_params(self, **params) -> self`：设置管道中所有步骤\n",
    "\n",
    "property 如下：\n",
    "- `named_steps(self) -> dict`：返回一个字典，包含每个步骤的名称和对应的转换器或模型。\n",
    "- `final_estimator(self) -> BaseEstimator`：返回管道中的最后一个模型，即最后一个步骤的转换器或模型。\n",
    "\n",
    "一个 class-method:\n",
    "- `from_estimators(cls, estimators: list) -> 'Pipeline'`：从一系列不带步骤名的估计器（转换器或模型）创建一个管道实例，便于快速构建管道。"
   ],
   "id": "6dca64918dccf5aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "直观上来看，`fit()` 方法需要对前面所有的转换器调用其 `fit_transform()` 方法，然后单独地对最后一个预测模型调用 `fit()` 方法。`predict()` 方法则需要对前面所有的转换器调用其 `transform()` 方法，然后单独地对最后一个预测模型调用 `predict()` 方法。",
   "id": "c7a6c48c662afff6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "然而，`Pipeline` 类有可能是一个完全的转换器，即最后一个步骤是一个转换器而不是预测模型。在这种情况下，`Pipeline` 类仍然可以正常工作，只是最后一步的 `predict()` 方法会被替换为 `transform()` 方法。因此，`transform()` 方法也是需要实现的，但为了防止错误地为预测器类的 `Pipeline` 实例调用 `transform()` 方法，或者反之，`predict()` 和 `transform()` 方法的开头都对最后一个步骤的类型进行了检查，确保其是一个转换器或预测模型。",
   "id": "18c1a1a4fa31df6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "以下是一个使用 `Pipeline` 类的示例，假设我们需要对特征矩阵进行插补、编码和缩放等预处理操作，然后使用一个分类模型进行训练和预测：",
   "id": "ecf1117e8c81761a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T03:05:48.903631Z",
     "start_time": "2025-08-11T03:05:48.898267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.mlfromscratch.compose import Pipeline\n",
    "from src.mlfromscratch.preprocessing.scaler import StandardScaler\n",
    "from src.mlfromscratch.preprocessing.imputer import SimpleImputer\n",
    "from src.mlfromscratch.metrics.classification import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array([[0, 1], [1, 0], [1, 1], [0, 0]])\n",
    "y_train = np.array([0, 1, 1, 0])\n",
    "X_test = np.array([[0, 1], [1, 0], [1, 1], [0, 0]])\n",
    "y_test = np.array([0, 1, 1, 0])\n",
    "\n",
    "classifier = MyClassifier()  # 假设 MyClassifier 是一个分类模型类\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # 插补缺失值\n",
    "    ('scaler', StandardScaler()),  # 标准化缩放\n",
    "    ('classifier', classifier)  # 分类模型\n",
    "])\n",
    "# 训练管道\n",
    "pipeline.fit(X_train, y_train)  # X_train 是特征矩阵，y_train 是标签向量\n",
    "# 预测结果\n",
    "y_pred = pipeline.predict(X_test)  # X_test 是测试特征矩阵\n",
    "# 计算评估指标\n",
    "accuracy = accuracy_score(y_test, y_pred)  # y_test 是测试标签向量\n",
    "print(f\"管道的准确率: {accuracy}\")"
   ],
   "id": "b6d4077e84aec366",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "管道的准确率: 0.25\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ColumnTransformer",
   "id": "2388ac0ae09bd7a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "有了 `Pipeline` 类的基础，我们可以进一步实现 `ColumnTransformer` 类，用于对特征矩阵的不同列进行不同的预处理操作。`ColumnTransformer` 类允许我们为每一列指定一个转换器，并将这些转换器组合在一起，形成一个完整的工作流。",
   "id": "7d6b1773bb31b1ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "直观上看，`ColumnTransformer` 类需要将多个转换器按列组���在一起，即需要传入一系列转换器和对应的列索引或列名称。与 `Pipeline` 不同的是，`ColumnTransformer` 只能是一个转换器，而不能是一个预测模型。因此，`ColumnTransformer` 需要继承 `TransformerMixin` 类，并实现 `fit()`、`transform()` 方法，来统一地处理多个转换器的训练和转换。",
   "id": "881af242f4950e99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "另外，`ColumnTransformer` 是完全并行的，即对于每一个列，最多只能对应一个转换器，如果想要对某一列进行多个转换器的处理，可以将这些转换器组合成一个管道，然后再将这个管道作为一个转换器传入 `ColumnTransformer`。这样可以确保每一列只对应一个转换器，避免了多重转换器对同一列的冲突。",
   "id": "b7ab1fc2e493abeb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`ColumnTransformer` 类的实现位于 `src/mlfromscratch/compose/_column_transformer.py` 中，私有属性如下：\n",
    "- `transformers`：存储转换器和对应的列索引或列\n",
    "- `remainder`：指定未被转换器处理的列的处理方式，默认为 `'drop'`，即丢弃未被处理的列。\n",
    "- `fitted_transformers_`：存储每个转换器的拟合结果，便于后续的转换。\n",
    "\n",
    "方法如下：\n",
    "- `__init__(self, transformers: list, remainder: str = 'drop')`：初始化列转换器，传入转换器和对应的列索引或列名称，以及未被处理的列的处理方式。\n",
    "- `fit(self, X: np.ndarray, y: Optional[np.ndarray] = None, **fit_params) -> self`：按列调用每个转换器的 `fit()` 方法，并将结果存储在 `self.fitted_transformers_` 中。\n",
    "- `transform(self, X: np.ndarray) -> np.ndarray`：按列调用每个转换器的 `transform()` 方法，并将结果组合在一起，返回最终的特征矩阵。"
   ],
   "id": "8530e3958f5b44b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "以下是一个使用 `ColumnTransformer` 类的示例，假设我们需要对特征矩阵的不同列进行不同的预处理操作，如对数值列进行标准化，对类别列进行独热编码：",
   "id": "3d63e800296d20fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T03:05:48.939995Z",
     "start_time": "2025-08-11T03:05:48.931096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用 ColumnTransformer 进行混合数据类型的预处理\n",
    "from src.mlfromscratch.compose import ColumnTransformer\n",
    "from src.mlfromscratch.preprocessing.scaler import StandardScaler\n",
    "from src.mlfromscratch.preprocessing.encoder import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# 创建混合类型的示例数据\n",
    "# 前两列是数值特征，后两列是类别特征\n",
    "X_mixed = np.array([\n",
    "    [1.0, 2.5, 'A', 'X'],\n",
    "    [2.0, 3.1, 'B', 'Y'],\n",
    "    [1.5, 2.8, 'A', 'Z'],\n",
    "    [3.0, 4.0, 'C', 'X'],\n",
    "    [2.5, 3.5, 'B', 'Y'],\n",
    "    [1.8, 2.2, 'A', 'Z']\n",
    "])\n",
    "\n",
    "print(\"原始数据:\")\n",
    "print(X_mixed)\n",
    "print(f\"数据形状: {X_mixed.shape}\")\n",
    "\n",
    "# 创建列转换器\n",
    "# 对列 0,1 进行标准化，对列 2,3 进行独热编码\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), [0, 1]),        # 数值列标准化\n",
    "        ('encoder', OneHotEncoder(), [2, 3])         # 类别列独热编码\n",
    "    ],\n",
    "    remainder='drop'  # 未指定的列将被丢弃\n",
    ")\n",
    "\n",
    "# 训练列转换器\n",
    "column_transformer.fit(X_mixed)\n",
    "print(\"\\n列转换器训练完成\")\n",
    "\n",
    "# 检查拟合的列转换器\n",
    "print(\"\\n拟合的转换器信息:\")\n",
    "for name, transformer, columns in column_transformer.fitted_transformers_:\n",
    "    print(f\"  {name}: {type(transformer).__name__} 应用于列 {columns}\")\n",
    "    if hasattr(transformer, 'mean_'):\n",
    "        print(f\"    均值: {transformer.mean_}\")\n",
    "        print(f\"    标准差: {transformer.scale_}\")\n",
    "    if hasattr(transformer, 'categories_'):\n",
    "        print(f\"    类别: {transformer.categories_}\")\n",
    "\n",
    "# 转换数据\n",
    "X_transformed = column_transformer.transform(X_mixed)\n",
    "\n",
    "print(f\"\\n转换后的数据:\")\n",
    "print(X_transformed)\n",
    "print(f\"转换后的数据形状: {X_transformed.shape}\")\n",
    "\n",
    "# 验证转换结果\n",
    "print(\"\\n验证转换结果:\")\n",
    "print(\"前两列应该是标准化后的数值（均值≈0，标准差≈1）\")\n",
    "print(f\"前两列的均值: {np.mean(X_transformed[:, :2], axis=0)}\")\n",
    "print(f\"前两列的标准差: {np.std(X_transformed[:, :2], axis=0)}\")\n",
    "\n",
    "print(\"\\n后面的列应该是独热编码的结果（只包含0和1）\")\n",
    "print(f\"后面列的唯一值: {np.unique(X_transformed[:, 2:])}\")\n",
    "\n",
    "# 测试 remainder='passthrough' 的情况\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"测试 remainder='passthrough' 的情况\")\n",
    "\n",
    "# 创建一个包含更多列的数据\n",
    "X_more_cols = np.array([\n",
    "    [1.0, 2.5, 'A', 'X', 10.0],\n",
    "    [2.0, 3.1, 'B', 'Y', 15.0],\n",
    "    [1.5, 2.8, 'A', 'Z', 12.0]\n",
    "])\n",
    "\n",
    "print(f\"原始数据形状: {X_more_cols.shape}\")\n",
    "\n",
    "# 只对部分列应用转换器，剩余列保持不变\n",
    "column_transformer_passthrough = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), [0, 1]),        # 只对前两列标准化\n",
    "    ],\n",
    "    remainder='passthrough'  # 未指定的列将保持原样\n",
    ")\n",
    "\n",
    "# 训练并转换\n",
    "column_transformer_passthrough.fit(X_more_cols)\n",
    "X_passthrough = column_transformer_passthrough.transform(X_more_cols)\n",
    "\n",
    "print(f\"转换后的数据形状: {X_passthrough.shape}\")\n",
    "print(\"转换后的数据:\")\n",
    "print(X_passthrough)\n",
    "print(\"前两列被标准化，后三列保持原样\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ColumnTransformer 测试完成！\")\n"
   ],
   "id": "392f5398cede9be3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据:\n",
      "[['1.0' '2.5' 'A' 'X']\n",
      " ['2.0' '3.1' 'B' 'Y']\n",
      " ['1.5' '2.8' 'A' 'Z']\n",
      " ['3.0' '4.0' 'C' 'X']\n",
      " ['2.5' '3.5' 'B' 'Y']\n",
      " ['1.8' '2.2' 'A' 'Z']]\n",
      "数据形状: (6, 4)\n",
      "\n",
      "列转换器训练完成\n",
      "\n",
      "拟合的转换器信息:\n",
      "  scaler: StandardScaler 应用于列 [0, 1]\n",
      "    均值: [1.96666667 3.01666667]\n",
      "    标准差: [0.64978629 0.60392236]\n",
      "  encoder: OneHotEncoder 应用于列 [2, 3]\n",
      "    类别: [array(['A', 'B', 'C'], dtype='<U32'), array(['X', 'Y', 'Z'], dtype='<U32')]\n",
      "\n",
      "转换后的数据:\n",
      "[[-1.48766861 -0.85551835  1.          0.          0.          1.\n",
      "   0.          0.        ]\n",
      " [ 0.05129892  0.13798683  0.          1.          0.          0.\n",
      "   1.          0.        ]\n",
      " [-0.71818485 -0.35876576  1.          0.          0.          0.\n",
      "   0.          1.        ]\n",
      " [ 1.59026645  1.62824461  0.          0.          1.          1.\n",
      "   0.          0.        ]\n",
      " [ 0.82078268  0.80032362  0.          1.          0.          0.\n",
      "   1.          0.        ]\n",
      " [-0.25649459 -1.35227095  1.          0.          0.          0.\n",
      "   0.          1.        ]]\n",
      "转换后的数据形状: (6, 8)\n",
      "\n",
      "验证转换结果:\n",
      "前两列应该是标准化后的数值（均值≈0，标准差≈1）\n",
      "前两列的均值: [-1.48029737e-16  8.51170986e-16]\n",
      "前两列的标准差: [1. 1.]\n",
      "\n",
      "后面的列应该是独热编码的结果（只包含0和1）\n",
      "后面列的唯一值: [0. 1.]\n",
      "\n",
      "==================================================\n",
      "测试 remainder='passthrough' 的情况\n",
      "原始数据形状: (3, 5)\n",
      "转换后的数据形状: (3, 5)\n",
      "转换后的数据:\n",
      "[['-1.224744871391589' '-1.2247448713915863' 'A' 'X' '10.0']\n",
      " ['1.224744871391589' '1.2247448713915918' 'B' 'Y' '15.0']\n",
      " ['0.0' '1.8129866073473575e-15' 'A' 'Z' '12.0']]\n",
      "前两列被标准化，后三列保持原样\n",
      "\n",
      "==================================================\n",
      "ColumnTransformer 测试完成！\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Section 0.8: 进一步抽象——输入验证函数",
   "id": "cb44db44005175c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "很多情形下我们都需要对输入的数据，无论是特征矩阵还是标签向量，进行验证，以确保它们符合预期的格式和类型。这些验证通常包括：\n",
    "- 检查输入是否为 NumPy 数组或 Pandas DataFrame。\n",
    "- 检查输入的维度是否符合预期。\n",
    "- 检查输入的类型是否符合预期（如数值型、类别型等）。\n",
    "- 检查输入是否包含缺失值（NaN/Inf）。\n",
    "- 检查输入的标签是否为一维数组或向量。"
   ],
   "id": "b186c74f9a62ad9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "因此，设计一个通用的输入验证函数是非常有用的，它可以在模型训练和预测之前对输入数据进行验证，确保数据的质量和格式符合预期。这样可以避免在训练或预测过程中出现错误，提高代码的健壮性和可维护性。根据我们前面的验证内容的分析，单一验证函数 `validate_array` 的参数设计是显然的：\n",
    "- `X`：被验证内容（可能是特征矩阵或标签向量），类型为 NumPy 数组或 Pandas DataFrame。\n",
    "- `ensure_2d`：是否确保输入为二维数组，默认为 `True`。\n",
    "- `allow_nan`：是否允许输入包含 NaN 值，默认为 `False`。\n",
    "- `allow_inf`：是否允许输入包含无穷大（Inf）值，\n",
    "- `dtype`：内部需要将输入转换为的 NumPy 数据类型，默认为 `None`，即不进行类型转换。"
   ],
   "id": "2d2dc01419a3d413"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "进一步设计同时检验特征矩阵和标签向量的验证函数 `validate_X_y`，通过调用 `validate_array` 函数来验证特征矩阵和标签向量的格式和类型，并检测 `X` 和 `y` 的维度是否匹配。\n",
    "\n",
    "-----"
   ],
   "id": "351d03ca07fdd76b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Section 0.9: 报告的编写与部署",
   "id": "a3a894c6eb0854bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "使用 Jupyter Notebook 编写报告和内容展示。所有 `.ipynb` 文件都存放在 `/notebooks` 目录下。",
   "id": "34ffc03d2eba28b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "通过 Jupyter Notebook 与 Mkdocs 联动可以简单地将报告的内容部署在网页上。对于笔者而言，由于个人知识库项目在另一个仓库中，可以使用 Jupyter 的 `nbconvert` 命令将 `.ipynb` 文件转换为 Markdown 格式，然后使用脚本将 Markdown 文件定向输出到知识库的 `docs` 目录下。这样可以将报告的内容与知识库的内容进行整合，便于后续的维护和更新。\n",
    "\n",
    "-----"
   ],
   "id": "2bd867184ce5ea18"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
